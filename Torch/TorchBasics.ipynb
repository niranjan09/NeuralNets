{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11169MB, multi_processor_count=28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541367984.101689\n",
      "1541367984.4177346\n"
     ]
    }
   ],
   "source": [
    "print(time.time())\n",
    "A = np.random.rand(size, size).astype(np.float32)\n",
    "B = np.random.rand(size, size).astype(np.float32)\n",
    "C = A.dot(B)\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541368086.9258344\n",
      "1541368087.0910802\n"
     ]
    }
   ],
   "source": [
    "print(time.time())\n",
    "A = torch.rand(size, size).cuda()\n",
    "B = torch.rand(size, size).cuda()\n",
    "C = torch.mm(A, B)\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create zero matrix\n",
    "torch.zeros(5, 5, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4641e+21, 4.5556e-41, 1.4641e+21, 4.5556e-41, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create uninitialized matrix\n",
    "torch.empty(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construct tensor directly from data\n",
    "torch.tensor([5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7078,  1.3288,  1.2232,  2.7432,  0.6179],\n",
      "        [ 1.8823,  1.3913,  1.4289,  1.4856,  1.2451],\n",
      "        [ 0.9528,  1.8660,  1.6291,  0.7027,  0.2968],\n",
      "        [ 0.8592, -0.1816,  1.7505, -1.0943,  2.3067],\n",
      "        [ 1.8953,  1.1095,  1.2406,  0.7206,  2.9639]])\n",
      "[[ 1.7078449   1.3288391   1.2231958   2.7431757   0.61790967]\n",
      " [ 1.8823378   1.3913293   1.4289138   1.4856381   1.24515   ]\n",
      " [ 0.95280796  1.8660489   1.6290544   0.702707    0.29679626]\n",
      " [ 0.8592217  -0.18157816  1.750478   -1.0942705   2.306712  ]\n",
      " [ 1.8952966   1.1095088   1.2406056   0.72064996  2.9639225 ]]\n"
     ]
    }
   ],
   "source": [
    "#torch tensor to numpy array\n",
    "a = torch.randn(5, 5)\n",
    "b = a.numpy()\n",
    "#numpy array is changed even after this operation:\n",
    "a.add_(1)\n",
    "#add_ is in place addition\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7078,  1.3288,  1.2232,  2.7432,  0.6179],\n",
       "        [ 1.8823,  1.3913,  1.4289,  1.4856,  1.2451],\n",
       "        [ 0.9528,  1.8660,  1.6291,  0.7027,  0.2968],\n",
       "        [ 0.8592, -0.1816,  1.7505, -1.0943,  2.3067],\n",
       "        [ 1.8953,  1.1095,  1.2406,  0.7206,  2.9639]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating tensor from numpy\n",
    "c = torch.from_numpy(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7078,  2.3288,  2.2232,  3.7432,  1.6179],\n",
      "        [ 2.8823,  2.3913,  2.4289,  2.4856,  2.2452],\n",
      "        [ 1.9528,  2.8660,  2.6291,  1.7027,  1.2968],\n",
      "        [ 1.8592,  0.8184,  2.7505, -0.0943,  3.3067],\n",
      "        [ 2.8953,  2.1095,  2.2406,  1.7206,  3.9639]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#cuda tensors:\n",
    "#only this code part will be run if cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    #directly create on gpu\n",
    "    y = torch.ones(5, 5, device = device)\n",
    "    c = c.to(device)\n",
    "    d = c+y\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## as mentioned on site's tutorial: ##\n",
    "**  It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - torch.Tensor is the central class of the package. \n",
    " - If you set its attribute .requires_grad as True, it starts to track all operations on it. \n",
    " - When you finish your computation you can call .backward() and have all the gradients computed automatically\n",
    " - The gradient for this tensor will be accumulated into .grad attribute\n",
    " - use .backward function to get derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.FloatTensor(5, 5),requires_grad = True)\n",
    "x = x+5\n",
    "y = x*x\n",
    "y = y+2\n",
    "z = y.mean()\n",
    "z.backward()\n",
    "print(z.grad)\n",
    "#tensors created by users have grad_fn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:H-DeepIE]",
   "language": "python",
   "name": "conda-env-H-DeepIE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
